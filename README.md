âœ¨ğŸš¦ gesture-based-driving-simulation âœ‹ğŸï¸

Control your car simulation with just your hands ğŸ™Œ â€” Brake ğŸ›‘ & Accelerate ğŸï¸ using AI-powered real-time hand gesture recognition ğŸ¤–âœ¨.

ğŸŒŸ Table of Contents

ğŸ¯ Motivation & Vision

ğŸ“– Introduction

âœ¨ Features

ğŸ›  Tech Stack

ğŸ“‚ Project Structure

âš™ï¸ How It Works

ğŸš€ Installation & Setup (macOS ğŸ)

â–¶ï¸ Usage

ğŸ“¸ Hand Landmarks Explained

ğŸŒ Applications

ğŸ“ˆ Future Scope

âš¡ Challenges & Learnings

ğŸ¤ Contributions

ğŸ“œ License

ğŸ’¡ Conclusion

ğŸ™ Acknowledgments

ğŸ¯ Motivation & Vision ğŸš€

Humanâ€“computer interaction (HCI) has always been defined by devices:
âŒ¨ï¸ Keyboards, ğŸ–±ï¸ Mice, ğŸ® Controllers.

Butâ€¦ what if our body itself could be the controller? ğŸ¤”

The vision of Gesture-Drive-AI is to remove physical barriers and build an intuitive, touchless interface where machines understand human gestures naturally.

ğŸ‘‰ This project is not just about driving games ğŸ®ğŸš— â€” itâ€™s about pushing forward towards:

ğŸ•¶ï¸ Immersive AR/VR experiences

â™¿ Accessibility-first interfaces for all users

ğŸ’¡ Smart homes & IoT controlled with gestures

ğŸŒ A future where gestures become a universal language for machines

ğŸ“– Introduction ğŸ’¡

Gesture-Drive-AI is a Python-based project that uses:

Computer Vision (OpenCV) ğŸ“¸ to process video

MediaPipe Hand Tracking âœ‹ to detect 21 hand landmarks

DirectKeys Automation âŒ¨ï¸ to simulate keypresses

Together, they form a gesture-based driving control system where:

âœ‹ Raise hand â†’ Gas ğŸï¸

âœ‹ Different pose â†’ Brake ğŸ›‘

âš¡ All in real-time, with low latency and visual feedback overlays.

âœ¨ Features ğŸŒŸ

ğŸ¥ Real-Time Tracking â†’ MediaPipe detects 21 landmarks

âœ‹ Gesture Recognition â†’ Map hand poses to actions

âŒ¨ï¸ Keyboard Input Simulation â†’ No hardware controllers needed

ğŸ›‘ Brake Gesture & ğŸï¸ Accelerator Gesture

ğŸ–¼ï¸ Visual Feedback with OpenCV â†’ Overlays "BRAKE" / "GAS"

âš¡ Ultra Responsive â†’ Minimal delay

ğŸ”§ Extendable â†’ Add more gestures (e.g., Steering Left/Right)

ğŸ•¹ï¸ Works with Driving Games â†’ Any game that uses keyboard input

| Technology                 | Purpose                              | Emoji |
| -------------------------- | ------------------------------------ | ----- |
| **Python ğŸ**              | Core programming language            | ğŸŸ¦    |
| **OpenCV ğŸ“¸**              | Real-time video capture & processing | ğŸ¥    |
| **MediaPipe âœ‹**            | 21-point hand landmark detection     | ğŸ–ï¸   |
| **NumPy ğŸ”¢**               | Numerical operations                 | ğŸ“Š    |
| **DirectKeys / PyAuto âŒ¨ï¸** | Key press simulation                 | ğŸ®    |
| **Time â±ï¸**                | Delay & timing control               | âŒš     |

Gesture-Drive-AI/
â”‚
â”œâ”€â”€ main.py              # ğŸ¯ Core script: CV + gesture mapping
â”œâ”€â”€ directkeys.py        # âŒ¨ï¸ Key press simulation
â”œâ”€â”€ hand_landmarks.png   # âœ‹ MediaPipe hand landmark reference
â”œâ”€â”€ step.txt             # ğŸ“ Step-wise gesture logic
â””â”€â”€ README.md            # ğŸ“– Documentation

âš™ï¸ How It Works ğŸ”

Capture Video ğŸ¥ â€“ Webcam feed using OpenCV

Hand Detection âœ‹ â€“ MediaPipe locates 21 hand points

Gesture Recognition ğŸ” â€“ Identify if gesture = Brake or Accelerator

Map to Keypress âŒ¨ï¸ â€“ DirectKeys simulates keystrokes

Overlay Feedback ğŸ–¼ï¸ â€“ OpenCV shows "BRAKE" / "GAS" in green box

Key Release ğŸ”„ â€“ Ensures smooth switching between gestures

ğŸ“Š Flow:
ğŸ–ï¸ â†’ ğŸ“· â†’ âœ‹ â†’ ğŸ” â†’ âŒ¨ï¸ â†’ ğŸš¦

ğŸš€ Installation & Setup on macOS ğŸğŸ’»

Hereâ€™s how to set up and run Gesture-Drive-AI on macOS:

1ï¸âƒ£ Update Homebrew & Python Environment ğŸ
brew update                  # Update Homebrew  
brew install python3         # Install Python3  
python3 --version            # Check Python version  
pip3 --version               # Check pip version  

2ï¸âƒ£ Create & Activate Virtual Environment ğŸ› ï¸
python3 -m venv gesture-drive-env   # Create virtual environment  
source gesture-drive-env/bin/activate   # Activate virtual environment  

3ï¸âƒ£ Clone the Repository ğŸ“‚
git clone https://github.com/your-username/gesture-drive-ai.git  
cd gesture-drive-ai  

4ï¸âƒ£ Install Dependencies ğŸ“¦
pip3 install --upgrade pip setuptools wheel   # Upgrade pip & tools  
pip3 install opencv-python mediapipe numpy    # Install project dependencies  


âš¡ Optional (for M1/M2 Macs if cv2 fails):

brew install opencv  
pip3 install opencv-contrib-python  

5ï¸âƒ£ Allow Webcam Permissions ğŸ¥

On macOS, OpenCV needs camera access:

ğŸ‘‰ Go to System Preferences â†’ Security & Privacy â†’ Camera â†’ Enable Python3

Check available cameras:

system_profiler SPCameraDataType  

6ï¸âƒ£ Run the Program â–¶ï¸
python3 main.py  

7ï¸âƒ£ Test in Driving Simulation ğŸ®

Open your driving game

Use gestures ğŸ™Œ to Brake ğŸ›‘ and Accelerate ğŸï¸

8ï¸âƒ£ Deactivate Virtual Environment âŒ
deactivate  

â–¶ï¸ Usage ğŸ¯

âœ‹ Show hand in webcam

ğŸŸ¥ Perform Brake Gesture â†’ Activates Brake ğŸ›‘

ğŸŸ© Perform Accelerator Gesture â†’ Activates Gas ğŸï¸

ğŸ–¼ï¸ Watch visual overlay feedback (rectangle + text)

ğŸš¦ Enjoy hands-free immersive driving ğŸ‰

ğŸ“¸ Hand Landmarks Explained âœ‹

MediaPipe tracks 21 landmarks per hand:

0 â†’ Wrist âŒš

4 â†’ Thumb tip ğŸ‘

8 â†’ Index fingertip â˜ï¸

12 â†’ Middle fingertip âœŒï¸

16 â†’ Ring fingertip âœ‹

20 â†’ Pinky fingertip ğŸ¤Ÿ

ğŸ“Œ See hand_landmarks.png for reference.

ğŸŒ Applications ğŸ”®

ğŸ® Gaming â†’ AI-driven controller-free gameplay
ğŸ•¶ï¸ AR/VR â†’ Natural interactions in immersive environments
â™¿ Accessibility â†’ For people with limited mobility
ğŸ’¡ IoT / Smart Homes â†’ Gesture-controlled appliances
ğŸ“Š Presentations â†’ Slide navigation using gestures
ğŸ¼ Media Control â†’ Play/Pause with hand signs

ğŸ“ˆ Future Scope ğŸš€

ğŸ”„ Steering Gesture Controls (Left/Right) â†”ï¸

ğŸ¤– Train custom ML gesture models

ğŸ™Œ Dual-hand gesture support

ğŸ¤ Hybrid Voice + Gesture system

ğŸ–¼ï¸ GUI with live gesture previews

âš¡ Challenges & Learnings ğŸ’­

âœ”ï¸ Real-time latency optimization âš¡
âœ”ï¸ Avoiding false positives in detection ğŸ¯
âœ”ï¸ Mapping 21 landmarks into simple actions âœ‹
âœ”ï¸ Creating a reliable DirectKeys module âŒ¨ï¸

ğŸ¤ Contributions ğŸ™Œ

We â¤ï¸ contributions!

ğŸ´ Fork repo

ğŸŒ¿ Create branch

ğŸ’¾ Commit changes

ğŸ”„ PR for review

ğŸ“œ License ğŸ“‘

MIT License âœ… â€“ Free to use, share, and improve.

ğŸ’¡ Conclusion âœ¨

Gesture-Drive-AI ğŸš¦ = AI ğŸ¤– + Computer Vision ğŸ‘€ + Human Gestures âœ‹ â†’ Future Interaction ğŸš€

This project proves:

ğŸŒ Tech can be touchless & immersive

ğŸ® Gaming can be next-level fun

â™¿ Interfaces can be inclusive & accessible

ğŸ’¡ AI can feel human-like

Raise your hand âœ‹.
Take control ğŸš—.
Step into the future of interaction.

ğŸ™ Acknowledgments ğŸ’

ğŸ¥ OpenCV
 â€“ Real-time CV library

âœ‹ MediaPipe
 â€“ Hand tracking magic

ğŸ Python community â€“ Open-source ecosystem

ğŸ’¡ Inspiration from AI + CV + HCI research








## ğŸ”„ New Update (v2) â€“ Smarter & Smoother Control

I recently updated the project to make it **more stable, more adaptive, and more user-friendly** ğŸš€

### âœ¨ Key Enhancements:
- ğŸ“ **Resolution-independent control** â€“ works on any screen size  
- âœ‹ **Improved gesture classification** â€“ detects fingers up/down reliably  
- âš¡ **Debouncing logic** â€“ prevents false triggers with confirm frames & cooldown  
- ğŸ”„ **State machine stability** â€“ smoother transition between Brake ğŸ›‘ and Gas ğŸï¸  
- ğŸ–¼ï¸ **Visual UI feedback** â€“ glowing Brake/Gas indicators on screen  
- âœ… **Safe shutdown** â€“ prevents stuck keys on exit  

Check out the updated [`main.py`](main.py) ğŸ‘ˆ

